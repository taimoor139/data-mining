{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interestingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interestingness through Market-Basket analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Market Basket Analysis is one of the key techniques used by large retailers to uncover associations between items. It works by looking for combinations of items that occur together frequently in transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association Rules are widely used to analyze retail basket or transaction data, and are intended to identify strong rules discovered in transaction data using measures of interestingness, based on the concept of strong rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Apriori algorithm generates association rules for a given data set. An association rule implies that if an item A occurs, then item B also occurs with a certain probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Apriori algorithm generates association rules for a given data set. An association rule implies that if an item A occurs, then item B also occurs with a certain probability. Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Images/market_basket.v1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above seven transactions from a clothing store is shown. Each transaction shows items bought in that transaction. We can represent our items as an item set as follows\n",
    "\n",
    "$$ I = (i_1,i2,..., in) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        \n",
    "In this case it will be:\n",
    "\n",
    "                               \n",
    "                                {T-shirt,Trousers,Belt,Jacket,Gloves,Sneakers}\n",
    "\n",
    "A transaction is represented by the following expression:\n",
    "\n",
    "$$  T = {t_1,i_2,..., t_k} $$\n",
    "\n",
    "For instance\n",
    "\n",
    "                                        T = {T-shirt,Trousers,Belt}\n",
    "\n",
    "Then, an association rule is defined as an implication of the form:\n",
    "\n",
    "$$ X=>Y, where  \\quad  X ,  Y \\subset I  \\quad and \\quad X \\cap Y = 0 $$\n",
    "\n",
    "For instance,\n",
    "                                   \n",
    "                                             {T-shirt, Trousers} => {Belt}\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interestingness Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support\n",
    "- Confidence\n",
    "- Lift\n",
    "- Conviction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support is a measure of how frequently the itemset appears in the dataset.\n",
    "\n",
    "$$ supp(X=>Y) = \\frac{X\\cap Y}{n}  $$\n",
    "\n",
    "In other words, support is the number of transactions with both X and Y divided by the total number of records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task1\n",
    "\n",
    "Calculate the support of the following rules.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some association rules with their supports calculated.\n",
    "\n",
    "$ supp(Trousers => Jacket) $\n",
    "\n",
    "$ supp(T-shirt => Trousers) $\n",
    "\n",
    "$ supp(Trousers => Belt) $\n",
    "\n",
    "$ supp(T-shirt => Belt) $\n",
    "\n",
    "$ supp(T-shirt,Trousers => Belt ) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an association rule X => Y, given that X occured, confidence is the frequency of Y happening. Mathematically, it is defined as follows:\n",
    "\n",
    "$$ conf(X=>Y) = \\frac{supp(X,Y)}{supp(X)} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task2\n",
    "\n",
    "Calculate the confidence of the following rules.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ conf(Sneaekrs => T-shirt)  $\n",
    "\n",
    "$ conf(T-shirt => Jacket)  $\n",
    "\n",
    "$ conf( \\{Trousers, Belt\\} => Sneakers)  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lift is the ratio of the observed support to that expected if X and Y were independent. Lift is defined as follows:\n",
    "\n",
    "$$ lift(X=>Y) = \\frac{supp(X , Y)}{supp(X)supp(Y)} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task3\n",
    "\n",
    "Calculate the lift of the following rules.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ lift(Trousers => Jacket)  $\n",
    "\n",
    "$ lift( \\{T-shirt,Belt\\} => Trousers)  $\n",
    "\n",
    "$ lift( T-shirt => Sneakers)  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conviction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviction can be interpreted as the ratio of the expected frequency that X occurs without Y (that is to say, the frequency that the rule makes an incorrect prediction) if X and Y were independent divided by the observed frequency of incorrect predictions. Mathematically, conviction is defined as follows:\n",
    "\n",
    "$$ conv(X=>Y) = \\frac{1-supp(Y)}{1-conf(X=>Y)}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task4\n",
    "\n",
    "Calculate the conviction of the following rules.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ conv(Trousers => Jacket)  $\n",
    "\n",
    "$ conv( \\{T-shirt,Belt\\} => Trousers)  $\n",
    "\n",
    "$ conv( T-shirt => Sneakers)  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing interestingness measures on a real-world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 15010 records(transactions) each with four columns. The description of the columns are as follows:\n",
    "\n",
    "- Date: Indicates date of trasaction (YYYY-MM-DD format). It ranges from 30/10/2016 to 09/04/2017\n",
    "- Time: Time of transaction (HH:MM:SS format)\n",
    "- Transaction: Categorical variable which allows to differentiate between transactions. Those rows that share the same transaction code belong to the same transaction. \n",
    "- Item: Categorical variables shows items of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('BreadBasket_DMS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task5\n",
    "\n",
    "- Plot the items against their corresponding frequencies as a bar plot.\n",
    "\n",
    "- Plot number of transactions per month.\n",
    "\n",
    "- Plot number of transactions per weekday.\n",
    "\n",
    "- Plot number of transactions per hour.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori is an algorithm for frequent item set mining and association rule learning over transactional databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Apriori0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Create a frequency table of all the items that occur in all the transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Apriori.v1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- We know that only those elements are significant for which the support is greater than or equal to the threshold support.Here, support threshold is 50%, hence only those items are significant which occur in more than three transactions and such items are Onion(O), Potato(P), Burger(B), and Milk(M). Therefore, we are left with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Apriori.v2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- The next step is to make all the possible pairs of the significant items keeping in mind that the order doesn’t matter, i.e., AB is same as BA. To do this, take the first item and pair it with all the others such as OP, OB, OM. Similarly, consider the second item and pair it with preceding items, i.e., PB, PM. We are only considering the preceding items because PO (same as OP) already exists. So, all the pairs in our example are OP, OB, OM, PB, PM, BM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- We will now count the occurrences of each pair in all the transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Apriori.v4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Again only those itemsets are significant which cross the support threshold, and those are OP, OB, PB, and PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Now let’s say we would like to look for a set of three items that are purchased together. We will use the itemsets found in step 5 and create a set of 3 items.\n",
    "\n",
    "To create a set of 3 items another rule, called self-join is required. It says that from the item pairs OP, OB, PB and PM we look for two pairs with the identical first letter and so we get\n",
    "\n",
    "OP and OB, this gives OPB\n",
    "PB and PM, this gives PBM\n",
    "Next, we find the frequency for these two itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Apriori.v6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python apriori library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  efficient_apriori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_itemset = data.groupby('Transaction')['Item'].apply(pd.Series.tolist).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_itemset)):\n",
    "    data_itemset[i] = tuple(data_itemset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets, rules = apriori(data_itemset[0:], min_support=.01,  min_confidence=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task6\n",
    "\n",
    "- Run apriori algorithm for different min_support and a fixed min_confidence and plot a graph with x axis min_support and y-axis to be the number of rules generated.\n",
    "\n",
    "\n",
    "- Run apriori algorithm for different min_confidence and a fixed min_support and plot a graph with x axis min_support and y-axis to be the number of rules generated.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(rules, rules_to_show):\n",
    "  import networkx as nx  \n",
    "  G1 = nx.DiGraph()\n",
    "   \n",
    "  color_map=[]\n",
    "  N = 50\n",
    "  colors = np.random.rand(N)    \n",
    "  strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']   \n",
    "   \n",
    "   \n",
    "  for i in range (rules_to_show):      \n",
    "    G1.add_nodes_from([\"R\"+str(i)])\n",
    "    \n",
    "     \n",
    "    for a in rules[i].lhs:\n",
    "                \n",
    "        G1.add_nodes_from([a])\n",
    "        \n",
    "        G1.add_edge(a, \"R\"+str(i), color=colors[i] , weight = 2)\n",
    "       \n",
    "    for c in rules[i].rhs:\n",
    "             \n",
    "#             G1.add_nodes_from(c)\n",
    "            \n",
    "            G1.add_edge(\"R\"+str(i), c, color=colors[i],  weight=2)\n",
    " \n",
    "  for node in G1:\n",
    "       found_a_string = False\n",
    "       for item in strs: \n",
    "           if node==item:\n",
    "                found_a_string = True\n",
    "       if found_a_string:\n",
    "            color_map.append('yellow')\n",
    "       else:\n",
    "            color_map.append('green')  \n",
    "  edges = G1.edges()\n",
    "  colors = [G1[u][v]['color'] for u,v in edges]\n",
    "  weights = [G1[u][v]['weight'] for u,v in edges]\n",
    " \n",
    "  pos = nx.spring_layout(G1, k=16, scale=1)\n",
    "  nx.draw(G1, pos, edges=edges, node_color = color_map, edge_color=colors, width=weights, font_size=16, with_labels=False)            \n",
    "#   nx.draw(G1)\n",
    "  for p in pos:  # raise text positions\n",
    "           pos[p][1] += 0.07\n",
    "  nx.draw_networkx_labels(G1, pos)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph (rules[30:40], 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task7\n",
    "\n",
    "Draw a graph that shows a consequence at center of the graph and precedence for each rule around it.\n",
    "\n",
    "More concretely consider consequence to be \"Tea\" and use rules with only one precedence and choose at most 12 rules.\n",
    "\n",
    "It should be something like the following graph but for \"Tea\" as a consequence.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Images/Graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task8\n",
    "\n",
    "In the default credit dataset try to find the followings.\n",
    "\n",
    "- Find a concise pattern.\n",
    "- Find a general pattern.\n",
    "- Find a peculiar pattern.\n",
    "\n",
    "Use the definition of conciseness, generality and peculiarity from the following paper.\n",
    "\n",
    "https://www.researchgate.net/publication/220566216_Interestingness_Measures_for_Data_Mining_A_Survey\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success' style=\"font-weight:bolder\">\n",
    "\n",
    "### Task9\n",
    "\n",
    "How is entrooy related to frequncy of itermsets? explain.\n",
    "\n",
    "To get help, refer to the following paper.\n",
    "\n",
    "https://www.researchgate.net/publication/221653139_Finding_low-entropy_sets_and_trees_from_binary_data/link/5414967d0cf2bb7347db32fa/download\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
